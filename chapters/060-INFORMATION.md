<div style='page-break-after: always; break-after: always;'></div>
# 6: INFORMATION

###### Information follows the same rules as everything else in nature.

##### **Synopsis:** Just as there an unfolding of reality via *chaos $\rightarrow$ pattern $\rightarrow$ order $\rightarrow$ integration*, there is an unfolding of *data $\rightarrow$ information $\rightarrow$ knowledge $\rightarrow$ understanding* or *sound $\rightarrow$ notes $\rightarrow$ scales $\rightarrow$ music*.  Order, being self-similar, naturally forms hierarchies, and the most stable of these hierarchies will be found at the optimal balance of the duality it exists within.  This not only applies to the emergence of awareness but to the biological structure through which awareness is expressed as individual consciousness, which inherits these same properties and processes.

##### **Keywords:** data, information, knowledge, understanding, noise, holarchies, memes
<center><img src='../Images/skinningchant.png' style='width:100%'/></center>
~(Image:\ Piano\ score\ of\ Faerie’s\ Aire\ and\ Death\ Waltz,\ from\ “A\ Tribute\ to\ Zdenko\ G.\ Fibich”.)~[^394]

[^394]: To hear the Colorado State Music Teachers Association performance of this “unplayable” score, visit https://youtu.be/sCgT94A7WgI?t=233

The same patterns that we see in the world around us we can find in the data from the world around us, thus transforming data into information.  How, then, do we define *data* and *information*?

## Data

To answer that, we can deduce that there is no data in the void of nothingness.  Data can only exist within a duality, which implies that there is energy, which means oscillation within finite boundaries in accordance with specific laws of existence.  So, what is the difference between data and existence itself? 

#### **Key 50:** Data is the static by-product of the movement of energy.

Data is static because all data is *stateless*, meaning data has no dependence on or relationship to anything in the past.  The process that generates the data may have such dependencies or relationships, which would make it a *stateful* process, but the data produced can only represent the *state* of a system and any given moment.  But what about historical data?  That data that is not in the present, but it is still data, correct?  

We can say that data is from the past or predicts the future, but to do that we have to not only add a dimension of time to the data, but we that have to relate the time dimensions across many data and in an order of time.  In other words, we have added *statefulness* to the *stateless* data.

Strictly speaking, it is the *datum* (singular for data) that is *stateless*, and the *data* (plural of datum) is a collection of *datum* over time or space, making it (potentially) stateful, depending how the data is used.  

Flipping a coin is *stateless*, as there is a 50/50 chance it will be heads or tails regardless of the result of the last 100 flips, but the odds of flipping 101 heads in a row is about 4&times;10<sup>-31</sup> because all the *states* of the 101 flips are seen as a larger *system*.

In its most basic form, data is numbers, words, units of measure, and other conceptual abstractions we invented to describe the phenomena within the spectrum of existence we can perceive and use. 

Suppose we accept the premise that everything that exists does so within the laws of creation.  In that case, we also need to accept that nothing exists that is not in perfect harmony with these laws because if they were not in perfect harmony with the laws, they would not exist.  Therefore, everything that can exist does, and everything that cannot exist does not, which implicitly tells us that:

#### **Key 51:** All data is valid.

Depending on what theory of reality you prefer, “everything” can mean all of that which exists at this moment, or, if you subscribe to the *Block Theory* of the Universe,  *Special Relativity*, or *Quantum Theory*, “everything” *must* mean everything that did, does, or will exist.  

The tholonic view is much simpler; if data is a by-product of existence, then something only exists if it produces data, regardless of whether anyone or anything can detect that data.  This is not strictly a tholonic concept, as this is essentially the definition of what science calls *Realism*.  Science defines *Realism* as  “*a positive epistemic attitude toward the content of our best theories and models, recommending belief in both observable and un-observable aspects of the world described by the sciences.*”, which is a typically abstruse science-ish way to say “evidence that supports a theory”, which boils down to “things have values”.

This view suggests that everything that ever did, does, or will exist currently exist somewhere in the grand scheme of reality, but in our corner of reality, the existence of that which *is* depends wholly on something’s ability to observe it.  This is true not just on a practical level, as we can’t say something exists if we have no awareness of that thing, but also on a technical level if there is any truth to the *Copenhagen interpretation of quantum mechanics* that the act of observation, of becoming aware of the data of an existence, is what causes the wave functions of quantum probability, i.e., archetypes, to “collapse” into material form.  We say that awareness causes these quantum archetypes to instantiate as matter.  

It may also be the case, at least according to Roger Penrose, the mathematical physicist considered to be “the most important physicist to work in relativity theory except for Einstein”[^395], that archetypes collapsing into matter is what creates consciousness, which is an instance of Awareness. This implies that the first consciousness, the first instance of Awareness, came into existence when the first *thing* came into existence. What that first thing was, be it the singularity of all mass, the 0-dimensional dot, or something else, given that it came into creation simultaneously with the Universe, we can safely say that Awareness is a universal property.

If we think about it, a black hole may be the perfect instance of “nothingness” in the sense that no  *thing* exists in a black hole, as any *thing* that enters a black hole is reduced to its fundamental particles, which get added to the soup of fundamental particles made of leptons and quarks and such.  These are the most basic building blocks of all matter and are themselves not composed of smaller particles.  As these particles act like waves and fields until they are observed by something or someone, and as there is nothing or no one to observe them in a black hole, everything must be just a bunch of un-collapsed wave functions, which are not particles.  That sounds as close to nothingness as it gets.

[^395]: Lee Smolin, a theoretical physicist and  founder of *Perimeter Institute*, and one of the most innovative theoretical physicists in the world, refers to Roger Penrose as someone who “is the most important physicist to work in relativity theory except for Einstein.  He is one of the very few people I’ve met in my life who, without reservation, I call a genius.” 

<img src='../Images/tatom_cuttri-1-4.png' style='float:right;width:20%'>Science doesn’t know which came first, awareness or archetype, so it could be $archetype + awareness = instance$ or it could be $archetype \rightarrow instance=awareness$.  In either case, we have some relationship between these properties because the archetypes contain the models of everything that can or will ever exist, and they produce data.  Still, it is not until we find or become aware of that data that some *thing* can be said to exist.  This is why we say that things that we can’t see but appear to create data are “real” and exist, such as quarks, black holes, 11-dimensional strings, and even time itself, because data says they exist.

**Where Here When Now**

This deserves a little more of an explanation.

The tholonic view is that the difference between what *does* exists and what *can* exist is the difference between the *here and now* and the  *not here and not now*.  We understand the single phenomena of *space-time* as having the properties of *space* and *time* which we also know as the properties of *where* and *when*.  

The state of something at any moment describes only that moment, not the past or the future, as data alone is *stateless*.  How it came to produce the present data and the data it will produce in the future depends on the patterns of the data, which is *stateful*.  

These terms are borrowed from the names of network protocols upon which the Internet is built. 

**Stateless** systems are self-contained and functions independently with only presently available data.  Stateless systems are high-speed, can be deployed quickly with the least amount of work, require minimum infrastructure, and are very robust and adaptable.  They are not well suited for integrated, intelligent, or data-heavy operations.  An example of stateless systems in nature would be inanimate objects such as sub-atomic particles,  elements, molecules, rocks, planets, stars, and things that increase in entropy (become more disordered).

**Stateful** systems depend on previously recorded data and store their own data for future stateful operations.  Stateful systems are more efficient for integrated, intelligent, or data-heavy operations and require more resources and memory.  An example of stateful systems in nature is living things, or things that evolve, such as DNA, galaxies, and things that decrease in entropy (become more ordered).

Of course, all systems in existence are made of systems within systems, each system depending on other systems to exist, so, in reality, all systems are a combination of stateless and stateful systems with each system’s statefullness or statelessness being relevant only to the context and scope of that system.  For example, a rock can be considered stateless in the scope of macro objects, even though it depends on the molecules it is composed of (which depend on the atoms).  DNA, while being stateful, is composed of stateless molecules, and so on.

<img src='../Images/statetreeBW.png' style='float:right;width:40%'>We see this same thing in the Internet, as the protocol on which the Internet is built, the Transmission Control Protocol (TCP), is stateful, as it must keep track of the entire “life” of a transmission; when it begins, how much has been sent, when it ends, etc.  However, the information being sent is stateless, as it is just a collection of data moving from point A to point B.  On top of TCP is the protocol to send and receive web pages; called HTTP (Hyper Text Transfer Protocol), which is stateless, but web applications (e.g., Google Maps) add an extra layer of architecture that uses HTTP to integrate stateless systems into create stateful systems stateless &rarr; stateful &rarr; stateless &rarr; stateful &rarr; &hellip;  This alternate layering of systems within systems is conceptually illustrated in the very fractal image above with stateless circles in black, and stateful circles in white.

How does this apply to the data and information on a space-time/existential level?

The present has no past or future.  This makes the present a *stateless* condition of *space-time* that has no past and no future, and its only temporal attribute is *now*.  Likewise, the only spacial attribute of *now* can be *here*.  In this context, *here* refers to the *system* of *space-time*, a domain that includes the entire Universe in all its dimensions.  You may be thinking, “If I am *here* and you are *there*, then there is obviously a *there* there”, and that would be correct if *here* referred to the system, or subsystem, of an observer whose domain is limited by their ability to perceive.  From the perspective of the Universe or even the Multiverse, there can only be a single *here* for beyond *here* is nothingness.  Within that single *here* that can be multiple *heres*, and within each of those *heres*, there are more *heres*, ad infinitum.  This is somewhat similar to Relativity’s claim that the perception of time is the same for everyone regardless of how their time appears to others.  In the same way, everyone’s *here* is the same regardless of where their *here* is and of other *heres*, or the *there-nows*, appear to them.

Our ability to grasp the concepts of *past* and *future* allows us to understand patterns and change, which allows us to plan and predict, but neither is “real”, at least in how we classically understand these concepts.  The *stateful* conditions of *where-when* are simply historical records of a once *here-now* of a past present.  Of course, we’ll have to expand our ideas of past and present if there is anything to those experiments that suggest the present can alter the past and the future can alter the present[^396].  This shouldn’t be a problem.  If we can redefined “real” as:

[^396]: Jacques, Vincent, E Wu, Frédéric Grosshans, François Treussart, Alain Aspect, Philippe Grangier, and Jean-François Roch. “**Experimental Realization of Wheeler’s Delayed-Choice Gedanken Experiment.**” Conference on Coherence and Quantum Optics, 2007.  https://doi.org/10.1364/cqo.2007.cwb4., https://arxiv.org/pdf/quant-ph/0610241.pdf

> Something is real when it is a necessary ingredient of a theory that correctly describes what we observe. **~Sabine Hossenfelder, theoretical physicist**

&hellip; then I am confident we can also redefined “cause”, “effect” and “time” to make it all fit.

Ironically, this scientific definition leaves the door wide open for some very liberal definitions of “real” once we begin to question the meaning of “observe” and “theory”.

Many books, theories, and speculations exist on the true nature of time.  We will take the simplest reductionist (and therefore most likely to be correct) approach and claim that *here* and *now* are not only *real*, but are the only aspects of *space-time* that are *real*.

<center><img src='../Images/states.png' style='width:90%'></center>

What was just said about the temporal aspect of space-time also applies to the spatial aspect of space-time.  A point of data is a 0-dimensional concept, but let’s imagine it as a red dot for this thought experiment.  In the image above, we see a single data and collections of data, but we clearly see patterns that are not dependent on past or future as we are seeing them now.  In this case, the data points are still *stateless* even though they create patterns that result from the *relationships* between the data points.  Hence, the relationship is *stateful*, but the data is still *stateless*. 

In the temporal case, data is produced in the *present*, the *now*.  In the spatial case, data is produced at a location, which would be the location where the data is from, but from the data’s perspective, the location is always *here*.  This sounds odd because we don’t think of data having a location, but it has a location in at least 2 domains.  The first domain is that of instantiation, such as matter or energy.  If we are measuring a desk, that desk has a location.  If we are measuring heat, we are measuring it at some location, etc.

<img src='../Images/datatri.png' style='float:right;width:40%'>The other domain is where any piece of data exists in the spectrum of all data, which we’ll call the *data-matrix*.  For example, take any number, such as 7.  7 is a piece of data that comes after 6 and before 8; that is its location in the spectrum of data.  Every piece of data that can exist is a distinct unit defined by limits and its relationship to other data.  Data *has* to come from that perfectly structured set of values, the *data-matrix*; otherwise, it would be useless, and math wouldn’t work.  When we measure anything, we are mapping something that exists in some state of chaos to a perfectly ordered set of data that never changes.  Suppose we measure something as 7, be it 7 degrees, 7 feet, or 7 days.  In that case, we are saying that whatever we measure equates via some definition, such as temperature, distance, or time, to a particular location in the conceptual landscape of the *data-matrix*.  The image above shows one way to view the relationship between the chaos of reality, the order of the data matrix, and the definitions we create that enable us to relate them.

<img src='../Images/timedots.png' style='float:right;width:40%'>There is the *stateful* relationship between *stateless* data at any point in time.  This collection of data points we’ll call a *data-frame*.  In every moment, a new data-frame is created, and our perception of the *differences* in these data-frames accounts for reality as we know it.  Reality is the difference between relationships in both space (relationships in a data-frame) and time (relationships between data-frames).  We are going to accept the current claim a “moment” of time is  10<sup>−44</sup> seconds, as this is *Planck time*, the time it takes a photon to travel the shortest length that can exist, which is *Planck’s length* (1.62 × 10<sup>-35</sup> meters).

All this was a fairly wide detour to simply say that what *does* exist exists in *here-how*, and what *can* exist exists in *here-when*.  In terms of data, we know we can splice the genes of a human toe into mouse genetics to get a mouse with a human toe growing out of its back, but a back-toed mouse does not exist (hopefully) in *here-now* and therefore is not currently producing data.  A back-toed-mouse *could* exist but currently does *not* exist.  As there is no *state* of back-toed-mouse, and as data is *stateless* and requires a *state* to exist, no data exists. 

#### **Key 52:** All data is valid, is only created in the present, and is stateless.

What, then, is information?  The classic and simplest definition is “*data that we can use to understand something*”, which is just another way of saying “*Information is data that has meaning*” but we need first to understand what “understand” means before we can understand what “information” means.  What we could say about information, which we mentioned earlier, is that information must be *stateful* because it consists of data of many *states*, giving it a “memory” of previous states and “knowledge” of their relationships.  We can at least say that *information* is the relationship between *data*.

What about *understanding*?  Again, the traditional meaning is *“the knowledge of why or how something happens or works”.* This is pretty unsatisfactory and quite arguably wrong.  At the risk of sounding Clinton-esque, debating what the definition of “is” is, the words *“use”* and *“understand”* are entirely subjective and offer no actual meaning.  With the word “work” defined as simply *“to function or operate according to design”*, this entire definition is vague, as best.

Can we come up with a better definition of the words *knowledge* and *understanding*?

To know something’s function and purpose is the fundamental goal of science, philosophy, and even religion, as these disciplines require a demonstrative understanding which we can see in their relative forms of reasoning.

Like in the dancing-woman-in-the-dots example, we can perceive something that is little more than subjective projection and has no basis in objective reality.  This human ability to “recognize” things in meaningless images brought about the famous Rorschach inkblot test, as it provides some insight into how a person perceives the world by their perception of patterns they project onto the random images.

In the world of philosophy, this knowledge-as-projection is exemplified in the *cow in the field problem* first posed by American philosopher Edmund Gettier.  It goes like this:

> A farmer is concerned his prize cow has gotten lost.  A neighbor comes to the farmer and tells him he saw the cow in his field.  To double-check,  the farmer visits the neighbor’s field and sees his cow’s familiar black-and-white shape.  Satisfied, he goes home.  The neighbor also decided to check.  The cow is in the field but hidden behind some large bushes.  However, a large sheet of black and white paper is caught in the bushes.  It is clear that the farmer saw this and thought it was his cow.  The question is then: even though the cow was in the field, was the farmer correct when he said he knew it was there?

This was meant as a criticism of the popular definition of *knowledge* as *justified true belief*, meaning if you believe something and it is both factually valid and verifiable, then that is *knowledge*.  This sounds like a terrifically misguided post-modern idea of knowledge because, by this definition, the dancing-woman-in-the-dots *is* knowledge, as it satisfies all 3 conditions.  By this definition, *understanding* is vulnerable to subjective perception, which has its own merits but is worthless, even destructive, when it comes to understanding the objective aspects of the laws of existence.  If we do not have concepts collectively agreed upon for sharing, we will quickly revert to confused cave dwellers.

This critique also applies to science because if “Something is real when it is a necessary ingredient of a theory that correctly describes what we observe”, then in the *cow in the field* problem, scientifically speaking; the cow *was* in the field… but, it wasn’t.

Simply *knowing* the details of a situation is not the same as *understanding* them.  We can see this in countless confusing or challenging situations that demand critical decisions that inevitably fall prey not to our understanding of the challenge but to our conscious or unconscious beliefs, desires, and fears.  We can see this difference even in less dramatic situations, such as knowing all the details about camping and understanding what camping entails or the difference between the map and the terrain.

A better definition of understanding might be “the knowledge of something sufficient enough to make verifiably accurate statements regarding said thing”.

## Verification

But this, too, falls short depending on what *verifiable* means.  For example, 4 people have to solve the following puzzle:

What is the following number in this sequence?  91715

Bob says “1”, and Carol says “3”.  Bob defends his answer by showing that 71 is 20 less than 91; therefore, 51, being 20 less than 71, is the obvious pattern.  Carol, however, says it is 3 because 917153 is, in fact, a sequence of numbers in *pi*.  Ted also says “1” because 9+1=10, 7+1=8, therefore 5+*x* = 6, so *x* must be 1.  Alice says “9” because that would result in 3 prime numbers, 11, 13, and 17 using the 2D lattice she made to solve the problem.

All 4 people have an understanding of the problem and the ways in which it can be solved, and therefore all 4 answers are verifiable.  It’s not unlike when you ask a child what 1+1 is, and she confidently answers “6”.  When asked why 1+1 = 6, she says: *“I had 1 white cat and 1 gray cat, now I have 6 cats; 2 white cats, 2 gray cats, a black cat, and a cat that is all colors”* referring to her 2 cats and their 4 new kittens.  Not only did 1+1 equal 6, but it came in many colors and was soft and cuddly.

As silly as this sounds, her answer was quite accurate given the context and the scope of a child’s understanding and the context of *“1 (female cat) + 1 (male cat)”*, which is not at all an irrelevant detail, especially to the cats.  We can see the “error” here as the child not being able to appropriately identify the differences between the overlapping contexts of math and animals.  We should not be quick to judge this child because we have to assume that even the greatest thinkers will make the same “error”, albeit with more complex contexts.  After all, this discernment is a product of our neurology, the brain being a big pattern recognition machine.  Unless we have the ultimate brain, we can’t recognize everything.

Understanding is contextual and only relevant to the degree to which it applies to the matter in question and why it was asked in the first place.  Even the concept of “1” is contextually relevant.  We may have 1 dollar or 1 day, but what does 1 mean if we say 1 puddle plus 1 puddle?  We either have 2 puddles, or, if they are connected, we have 1 big puddle, and now “2” is not the unit count of puddles, but the relative volume of the puddle, i.e., 1 puddle that is twice as large.  If we drop 1 rock into a lake, we have 1 wave function.  If we drop 2 rocks into a lake, we have 2 wave functions that interfere with each other.  So we could say:

“1”=<IMG src='../Images/math/335.svg' style='vertical-align:middle;height:12pt'/> as this is the general description of a wave.

“2”=<IMG src='../Images/math/336.svg' style='vertical-align:middle;height:22pt'/> as this is the description of two waves interfering with each other.

What happens if we take 1 particle traveling at *x* speed and smash it headfirst into another particle traveling at *x* speed?  You might think that the particles smash into each other at the speed of *2x*, but you’d be wrong if *x* was the speed of light because, at the speed of light *1+1 = 1*, at least according to the Theory of Relativity.[^46] More specifically, the product of the 2 opposing speeds, when multiplied together, can never *appear* to exceed *c*, the speed of light, so here 1+1 could equal any of the infinite values between 1 and 2.  

[^46]: Hossenfelder, Sabine.  “**Dear Dr.  B: Does the LHC Collide Protons at Twice the Speed of Light?”** Backreaction, 1 Jan.  1970, backreaction.  <https://blogspot.com/2019/04/dear-dr-b-does-lhc-collide-protons-at.html>

Other living creatures share our ability to count, the main difference being the concept and application of “counting”.  For example, fish can count in the sense that they can measure the relative size of a school of fish, so they have a concept of *greater than* and *less than*, at least.  This is a helpful skill as the size of the school is directly related to their chances of survival.  Frogs can count as well as perform addition; a female frog (from one species)  measures potential mates by the number of croaks they can make in a row, so at some level, she is calculating “Contestant #1 croaked 5 times, but contestant #2 croaked 6 times”, and because the males are competing, contestant #2 had to “count” the croaks of contestant #1, then add 1, and then count down his own 6 croaks [^312].

[^312]: Rose GJ. **“The numerical abilities of anurans and their neural correlates: insights from neuroethological studies of acoustic communication.”** Philos Trans R Soc Lond B Biol Sci. 2017 Feb 19;373(1740):20160512.  doi: 10.1098/rstb.2016.0512.  PMID: 29292359; PMCID: PMC5784039.

In many animals, there are *accumulator* or *counting* neurons whose job is to send out a signal every time something is *recognized*, and by *recognized*, we mean the information that can be processed by the rest of the brain, i.e., the neurological component of a concept.  A monkey will “count” the bananas in a tree, but it won’t “count” how many people in the plaza are wearing Gucci.  In some creatures, including humans and fruit flies, the *timeless*, or *tim*, gene is critical to the “counting” necessary for managing the inner circadian clock.  More sophisticated counting comes from networks of neurons collecting and sharing data.

Knowing how many bananas there are, or knowing that *n*+1 croaks are better than *n* croaks, is the application of information to some context, such as food or mating, and that is the definition of knowledge.

#### **Key 53:** Knowledge is the application of relevant information to a context.

Imagine how humans might count if/when our neurology is far more evolved and interconnected.  Will numbers seem quaint?  Will we one day be able to process information analogously rather than with discrete digits?  Nature is analog (or at least appears so), and analog systems solve problems as fast as physics allows, so perhaps that is inevitable, and one day, numbers will no longer be necessary.

Reality, as we know it, depends on the context of not only what is happening (stateless) but all that had happened before (stateful), in whatever contexts the contributing events happened in, most of which we can only speculate on.  Our understanding of anything can only be relative to our context and valid within that context.  

So, let’s modify the meaning of understanding to the following claim:

#### **Key 54:** Understanding is the knowledge of something sufficient enough to be able to make verifiably accurate statements regarding said thing within the context of its current application.

With this definition, Bob, Carol, Ted, and Alice can make statements based on their understanding, but none are verifiable unless we know why the question was asked.  If the point was to see if they had reasoning abilities, they were all right, and so was the little girl, according to their relative reasoning abilities.  The specific question itself is irrelevant, as any number of questions could be asked to get the same results.  If the point of the question was to try and recover the last digit of a telephone number, there’s a 10% chance any one answer is correct, including the little girl’s answer, and the question was still meaningless.

We can now answer the question, “How do we define *information*?” If we accept that all data is valid and is, therefore *information* that is merely undiscovered due to our limited understanding of its relevance to context, *information* now can be defined as the following claim:

#### **Key 55:** Information is relevant data that we know how, when, and where to apply, given our understanding of the application context.

In short, information is *relevant data*.

## Data to Information

Data, being an abstract by-product of everything, is, by itself, meaningless, just as the existence of matter is, by itself, meaningless.  Data alone is the conceptual equivalent of chaos.  It creates nothing and has no energy, meaning, direction, form, or pattern.  The only value that comes from data is in how it relates to a data-frame, the ordered system of archetypes that are numbers.

#### **Key 56:** Data alone is chaos.

Information, at least one form of it, is when we can find patterns or laws in the chaos of data or apply data to an existing pattern or law.  We can go so far as to say *information* is the result of energy being applied to data.

There are many examples of this in nature, of order emerging out of chaos.  One of the more straightforward examples is the *standing wave pattern*.

### Standing Wave Patterns

For those who do not know what a *standing wave pattern* (SWP) is, it is a stable pattern that results from cycles of energy transmitted as waves interacting with matter.

Here is a collection of SWPs created by placing white powder on a drum head and exposing that drum head to various stable sounds, like a single tone or a collection of single tones.  This process is called *cymatics*.

<center><img src='../Images/027-cymatics.png' style='width:100%'/></center>

Here are some more complex cymatic patterns from the 12 notes of the 1<sup>st</sup> octave of a piano.

<center><img src='../Images/notes.png' style='width:100%'/></center>

The difference between data and information is analogous to the difference between chaos and order, that difference being entropy and energy.  

<center><img src='../Images/ent-images-3.png' style='width:100%'/></center>

Above are two examples of this concept.  In the upper image, we show the example of some random data.  In the lower diagram, we show the evolution of what turns out to be a self-similar pattern (described using the *L-System* language).

**Raw data** is a form of low entropy chaos.  Why?  Because as these values have no context or meaning, they are nothing more than random, abstract symbols.  There is nothing they can “do”; data alone has no microstates.  Raw data is *potential* information, not *kinetic* information (to borrow the concepts of physics)

**Information** results from applying energy to analyze the data, producing limits, patterns, and relationships.  In the example in the image above, the context is that of simple math functions.  Information equates to *kinetic energy* because it is data that can be used.  From our raw data, we discover the relationship between these numbers.

**Knowledge** is then produced when we apply this information in some meaningful manner.  Knowledge equates to applying kinetic energy, such as running a motor or boiling water.  In this case, we have gained the knowledge of how these numbers relate to each other and can apply this knowledge to such things as the laws of motion, electricity, Relativity, etc.

**Understanding** is when we extend this knowledge to understand the larger perspective and how it may apply to other scopes and contexts.

**Noise** is when the growth reaches a point where no more contextually usable information exists.  This is a deterioration of that knowledge in that the amount of contextually unusable data from a *system* becomes so great that the relevant information is lost.  At this point, the system is simply one of chaos.  The knowledge we have gained is not lost, but the system we used to acquire it has reached its limit.  An example of this might be how when speed, gravity, or momentum get too big, Newtonian mechanics spits out garbage data, and you need to move to quantum gravity to find the order in the data.  On that note, it’s worth pointing out that Newton’s laws of motion, Relativity, and quantum theory operate in 3 different scopes which overlap and interact.  As mentioned previously, the laws of one scope may not be valid for another, so applying laws from one scope to another will introduce some garbage results.  Still, given that there are scopes within scopes, we may find the *uber*-scope that all these scopes exist within, something like the scope of the *Unified Field Theory* or the *Theory of Everything*.

Another point to consider is how all data, information, knowledge, and understanding that we acquire from investigating our reality are just as vulnerable to decay due to entropy as the matter that our reality is built from.  This is because all the above forms require matter to survive; the brain that holds this knowledge, the book it was written down in, the DNA it was encoded into, or any other form of recording will eventually deteriorate, taking with it the knowledge and eventually returning the data-matrix back to the chaos of the infinite pool of meaningless abstractions.  Sadly, history has many examples of the permanent destruction of knowledge, and it’s statistically inevitable that at some point in the future, humanity will be reduced to foraging barbarians, again, as has happened in the past.

We have moved from *data* to *information* to *knowledge* to *understanding* in the following manner, more or less.

- Data + *order* = information
- Information + *context* = knowledge
- Knowledge + *application* = understanding

What comes next?  How do all these *understandings* we have discovered relate to one another?

Attempting to answer this question gave rise to the entire field of Western philosophy.  The word *philosophy*, which literally means “love of wisdom”, was invented 2,600 years ago by the Greek mathematician, philosopher, and religious mystic, Pythagoras, as the field of study dedicated to understanding how reality is put together.  A few years later, Parmenides, perhaps the most profound and challenging thinker of the Greek philosophers, came up with the idea of categorizing all that was understood about existence.  Today this is called *ontology*, which is hierarchical in nature and comes from the Greek “the study of that which is”.

***Historical note:*** While Parmenides changed the course of philosophical thinking, many of his ideas were considered preposterous, such as the idea that all of reality is an illusion&hellip; which, after 2,600 years, with models like the *Simulation Theory* and the *Holographic Theory* of reality, is almost mainstream thinking.

> … unborn and imperishable, whole, unique, immovable, and without end.  It was not in the past, nor yet shall be, since it now is, altogether, one and continuous

He warned that the senses give us false information as they only sense the illusion of reality.  Only reason can be trusted.  This branded Parmenides as an “extremist”; today, he is still classified as an *extreme rationalist*.  Not surprisingly, his arguments were based on the rational premise that something either “is” or ”is not”&hellip; a recurring theme in history and this book.  Parmenides also appears to be the first Western philosopher that introduced a formal concept of *nothingness*.  His idea that the act of *becoming* is an incoherent concept is explained by his contemporary, Gorgias, in an argument that was reasonable for the time:

> What is cannot have come into being.  If it did, it came either from what is or what is not.  But it did not come from what is, since if it is existent it did not come to be but already is; nor from what is not, for the nonexistent cannot generate anything. **~Georgias**

In other words, something can’t come from nothing.  The tholonic model, as will be explained in painful detail, is precisely the opposite: everything comes from nothing.  Ironically, the tholonic model uses many of the same arguments and reasoning as Parmenides.

#### **Key 57:** All information is hierarchical.

Needless to say, there has been a lot of discussing, researching, and testing over the past thousands of years on the best way to organize or knowledge of “that which is”.

## Holarchies

In 1972, Ervin Laszlo, philosopher, theorist, and two-time Nobel Prize nominee, published “Evolutionary Systems Theory.  Introduction to Systems Philosophy: Toward a New Paradigm of Contemporary Thought”.[^47]In that book, he incorporates *Living Systems Theory* and the hierarchical structures of Mario Bunge, an Argentine philosopher and physicist and a giant in the field of semantics, ontology, epistemology, philosophy of science and ethics, and recipient of twenty-one honorary doctorates and four honorary professorships by universities from the Americas (North and South) and Europe.

[^47]: Laszlo, E., & Clark, J.  W.  (1973).  **Introduction to systems philosophy: Toward a new paradigm of contemporary thought**.  New York, NY: Harper Torchbooks.  ISBN: 0061317624 (ISBN13: 9780061317620)

Laszlo’s challenge was to provide a framework for understanding universal structures that span the scopes ranging from subatomic physics, biology, chemistry, organisms, and social systems to the cosmos.  Laszlo describes a hierarchical model of interconnected conceptual entities.  When one of these entities is acting as a *part* of a larger entity, it is called a *parton*, and when acting as a *whole* entity with its own parts, or *partons*, it is called a *holon*.

<img src='../Images/033-embeddedholons.png' style='float:right;width:32%'/>The *holon* represents the *wholeness of its nature*, and the *parton* represents an integrated *part* of the greater *holon*.  The hierarchical ordering of *holons/partons* is called a *holarchy*.  An example of this is the biological cell mentioned previously.  The cell itself would be a *holon*.  The transcoder and other components necessary for the cell to function would be considered *partons*.  Likewise, the transcoder is also a *holon* with its component *partons*, and the cell itself is a *parton* to, say, an organ.  This makes the holarchy fractal in nature, as the structure of the entire hierarchy is self-replicated in each holon.

The most fundamental properties of holons are:

- Each holon has its own parameters, laws, and context.
- A holon can spawn new holons as partons.
- Holons, or archetypes, are interdependent on one another (as stateful systems), as well as independent (as stateless systems).

#### **Key 58:** The structure of information is fractal (self-similar and redundant)

The holarchy is meant to be a map of all the concepts of archetypes we have collected, and it attempts to organize these concepts in a hierarchical fashion where each parton is a child of a holon.  Here we apply our concept of scope as each parent has properties that the child inherits, i.e., within the holon of *person,* you will only find *person* things and not *planet* things.  Each holon then has a unique scope, which defines the spectrum of possibilities for the partons of that holon.  Now that we have a scope, we can apply the Bell curve of probability for any particular holon.  

<center><img src='../Images/029-holarchy.png' style='width:100%'/></center>

The graphs above represent a tiny subsection of the Grand Holarchy of Everything.  The chart on the left shows a larger picture of how partons and holons relate.  The chart on the right shows one of the many paths that connect subatomic particles to the Multiverse.  

With a few tweaks to the previous *Super-Duper Graph of Reality* Bell curve and using a log scale rather than a linear one, the concepts used in the above holarchy fit nicely.

<center><img src='../Images/030-supercurve2.png' style='width:100%'/></center>

Some readers may think, “Hey, wait a minute” those aren’t the same axis!  What kind of Gaussian goofiness is going on here?” Well, that is partly true.  The first *Super-Duper Graph of Reality* chart shows the probability (x-axis) of where order (y-axis) will be more likely to emerge across the entire spectrum of existence, while this chart is limited to the scope of human perception.

If we assume that our perceptions of reality are reasonably compatible with reality as it actually exists (with all due respect to Parmenides), then, as probability would have it, we humans happen to be in the part of the spectrum where one would most expect to find life popping up, so, congratulations to us, we’re where we are supposed to be&hellip; probably.

Because the peak of the curve represents where the most “work” will be done (given the 2 poles that define the limits of the curve), it is also where energy will most likely be able to form sustainable patterns.  The peak of the curve also represents the most efficient expression of a holon’s purpose and function.  If we were electrons instead of humans, our archetypal holon would have the electron in the center because, as the electron *does* exist, it would naturally occupy that point where its existence is most likely, which is at the peak of the curve for the electron holon.  However, because life forms will tend to exist at the peak of the curve that spans from quark to Multiverse, perhaps we can speculate that life itself and the expression of consciousness that evolved from life is a very efficient expression of energy.  This is not to say that there are no other forms of life that may excel in this regard, especially where radically different contexts may apply.  Still, if there are other forms of life in our corner of the Universe, they will most likely appear within the same range of the curve.  More than appearing in the same area of the curve, they will probably appear similar to earthly life forms.  If the aliens ever land a UFO in Central Park, we will all be surprised and a bit disappointed, I suspect, when what emerges looks unimpressively human.  At least that is the opinion of the University of Edinburgh’s Astrobiology professor Charles S.  Cockell, as he spells out in his book *The Equations of Life: How Physics Shapes Evolution*.  However, by his same reasoning, there is a chance it could look like some of our own highly successful life forms, such as lice, crocodiles, duck-billed platypuses, horseshoe crabs, immortal jellyfish, or the highly intelligent octopus, to name a few.

<center><img src='../Images/aliens.png' style='width:100%'/></center>

Human-looking or not, all creations are subject to the three attributes of the holarchy as noted above; **negotiation** (cooperation or conflict), **definition** (limitations of environment and resources), and **contribution** (maintenance of sustainability).  Oxford University’s evolutionary biologist Sam Levin sums this idea up quite well in his paper “Darwin’s Aliens”:

>[Aliens, like humans] are made-up of a hierarchy of entities, which all cooperate to produce a [lifeform].  At each level of the organism there will be mechanisms in place to eliminate conflict, maintain cooperation, and keep the organism functioning.  We should expect [aliens] to have been favoured by similarly restrictive conditions [as us humans].  Thus, we can make specific predictions about the biological makeup of complex aliens.  [^48]

[^48]: Levin, Samuel & Scott, Thomas & Cooper, Helen & West, Stuart.  (2017).  **Darwin’s aliens.** International Journal of Astrobiology.  1-9.  10.1017/S1473550417000362.

We take the position that it is these same forces that apply to all existence, not simply biological life.

Another excellent example of both a holarchy and its self-similar nature is that of the neurological structure of the brain’s processing ability, along with the structure of language that evolved out of that structure.  This also shows examples of the various scopes through which instances are expressed.  The 1<sup>st</sup> column on the left is a hierarchical structure of a sentence.  The 2<sup>nd</sup> column shows the speed at which the brain processes each part of the hierarchy.  The 3<sup>rd</sup> column shows what (proposed) part of the brain is contributing to the overall process, and the 4<sup>th</sup> column shows the scope and size of that part of the brain.

<center><img src='../Images/language.png' style='width:100%'/></center>

## Memes

More recently, this holarchical model was applied to Richard Dawkins’s concept of a *meme*[^49].  A meme is defined as:

> an element of a culture or system of behavior passed from one individual to another by imitation or other non-genetic means.

In Dawkins own words[^50] :

> “Memes spread through the culture like genes spread through the gene pool.”

<center><img src='../Images/032-holongrid.png' style='width:70%'/></center>

[^49]: Dawkins, C.  R.  (2016).  **The selfish gene**.  Oxford: Oxford University Press.
[^50]: **Just for Hits - Richard Dawkins**.  (2013, June 22).  https://www.youtube.com/watch?v=T5DOiZ8Y3bs 

The relevance is the demonstration how the concept of a meme is incorporated into a holarchy.  The original version of the chart above comes from a paper on video games and their potential to increase intelligence.[^51] The interesting part is how Velikovsky puts the meme at the bottom of the cultural branch.  It is interesting because it defines a meme as a 7<sup>th</sup>-generation descendant component part, a particle, so to speak, of the *uber* concept of *culture*.  The meme here is analogous to what the electron is to the atom, the atom to the molecule, or the molecule to the object.  He also puts *ideas* down there as well, which may be consistent with the way he defines an idea.  In our case, we are defining *Ideas* (capital “I”), like forms, as the archetypal blueprint for many instances of ideas.  The idea of *“Let’s make a video game where people have to shoot each other”* is an instance of the archetypal Idea *“Individual or tribal competition and survival”*, which also spawns such concepts as sports, war, predatory capitalism, the idea of winning, etc.  The idea of *“If I sin, I will burn in hell”*, a very resilient and popular meme for thousands of years, is an instance of the archetypal Idea *“We are judged harshly by our superiors for being self-serving”*, which spawns such concepts as karma, judgment day, guilt, original sin, etc.

[^51]: Velikovsky, J.  T.  (1970, January 01).  **Flow Theory, Evolution & Creativity: Or, Fun & Games ** <https://dl.acm.org/citation.cfm?id=2677770>

The holarchy examples shown above are portrayed as 2-dimensional bifurcating trees.  This model hides a lot of information, for if we zoomed in, we would see that within each holon is a collection of holons that share an idea, purpose, function, etc.  Each holon has its own parameters, laws, context, etc., and each holon, therefore, has its own Bell curve that shows where it is best suited to “work”, such as the Bell curve of the human eye sensitivity, which would be one holon of “human eye”.

For consistency, here is the human eye sensitivity chart, which represents one aspect of a holon of *human eye* in the *bio* branch of the holarchy and its natural Bell curve of efficiency, or “work”.

<center><img src='../Images/031-eyecurve2.png' style='width:100%'/></center>

These Bell curves of probability are not shown, or even defined, in the holarchic model.  The reason is that the holarchic model does not have the explicit concept of a duality, though it's implied.  As a result, the holarchy cannot show how the Bell curve of a holon is made up of the integrated aggregate of the Bell curves of its partons within the context of the holon.  <img src='../Images/2earths.png' style='float:right;width:20%'/>It does show the parameters of the holon are defined by its parent, but the ultimate parent of the holarchy is the Multiverse, which is, in our view, the “bottom” of the hierarchy of reality as we know it as, and the “seed” of of the *tree of reality* begins with the first and smallest particle which is the 0-dimensional dot.  In some way, this is like arguing which is the “correct” way to view Earth, north at the “top”, or south at the “top”, but it does play an important role a little later.

What happens if we incorporate the idea of dualities into the holarchy?  Let’s see, but first, let’s look at some important concepts behind *structure*.
