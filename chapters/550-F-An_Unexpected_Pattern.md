<div style='page-break-after: always; break-after: always;'></div>

# Appendix F: An Unexpected Pattern

###### What is this pattern, and why does it exist?

In the course of writing this book, there was the need to generate sets of chaotic numbers from other sets of patterned numbers.  In one case, the results presented a very unexpected pattern.

Numbers were generated by periodically calculating the longitudinal position of the Sun and the Moon (from Earth’s coordinates of -34.61262S, -58.41048W, Buenos Aires, Argentina on the 24<sup>th</sup> of each month at 5:31:07 PM UT) down to 10<sup>-15</sup>  radians.  The individual digits of these two values were then concatenated or cross-summed.  For example, the Sun’s longitude in radians at one moment was 4.2430033683776855, and the Moon’s position at that moment was 2.399298667907715.  These were then cross-summed until they were reduced to a single-digit value.

- 4+2+4+3+0+0+3+3+6+8+3+7+7+6+8+5+5=**74**
- 2+3+9+9+2+9+8+6+6+7+9+0+7+7+1+5=**90**
- 74+90=**164**
- 1+6+4=**11**
- 1+1=**2**

Millions of samples were recorded and reduced to one number per sample.  The input data of the Son and Moon positions was perfectly non-random and linear, but the single cross-summed number series of data was “mostly random” according to the *Chi-squared* results of a randomness test[^195].  Below are the test results of the single-number data and the data from a random number generator (RNG) for comparison[^196].

[^195]: These tests are: monobit frequency test, block frequency test, runs test, longest run ones10000, binary matrix rank test, spectral test, non-overlapping template matching test, overlapping template matching test, Maurers universal statistic test, linear complexity test, serial test, approximate entropy test, cumulative sums test, random excursions test, random excursions variant test, cumulative sums test reverse.  These tests are provided by the National Institute of Standards and Technology as implemented by the program *testrandom.py* by Ilja Gerhardt, https://gerhardt.ch/random.php.  The numbers published here are the result of the program “ent”, a pseudo-random number sequence test program by John Walker of Fourmilab Switzerland, https://en.wikipedia.org/wiki/John_Walker_(programmer)
[^196]: Data generated with the command “ent” with the following variables: Is Intel CPU; AESNI Supported in instruction set; Format=Hex model=pure size = 1000 kilobytes XOR mode off XOR range mode; off Output to file x Hardware Random Seeding on. Non deterministic mode;  Reseed c_max=511;  Using RdRand as nondeterministic source; Total Entropy = 0.000000; Per bit Entropy = 0.000000 %

<center><img src='../Images/rng.png' style='width:100%'/></center>

Next, each single digit number (1-9) was assigned a color from the spectrum and then plotted such that each dot occupied one consecutive pixel on one line, and when that line was full, the plot advanced to the next line, just like a dot-matrix printer.  This was an extremely simple plot.  The below-left plot shows only one number being plotted at a time, and the below-right plot shows cumulative numbers.  The distribution of the numbers within the data set of 33,000,000 is shown in the bar chart.

The data was also tested against Benford’s law, which states that the 1<sup>st</sup> digit in a naturally occurring set of values will be distributed in a manner dependent on the log of that number.  We looked at 3 sets of data; 1) the crossed-sums of the Sun, 2) the crossed-sums of the Moon, and 3) the crossed-sums of the Sun and Moon combined.  We counted the number of each digit 1 through 9 in a data set of 33,575,635 data samples.  While the numbers were similar in the count, they were not similar enough to suggest an even distribution suc as we would see in random numbers, and therefore not in accordance with Benford’s law.  To see these totals, we plotted the difference between the lowest and highest counts (charts below) for each number 1-9.  As you can see, there is some very patterned behavior, especially in the first chart and even more so in the last charts, which also shows a unique pattern that only applies to prime numbers.

<center><img src='../Images/2cspos.png' style='width:100%'/></center>

Much to our surprise, this resulting pattern matches that of a *Fresnel diffraction*.

<center><img src='../Images/123456789comp.png' style='width:100%'/></center>

At the rate we were sampling, each position of each “planet” was only about 7x10<sup>-8</sup> radians further than the previous position sampled.  This equates to about 23 kilometers of movement for the Sun and only 64 millimeters of movement for the Moon.

When cross-summing numbers, the place of each digit is insignificant, so 123 and 321 are the same as they both cross-sum to 6.  Because all the digits in a cross-summed value have equal significance, the slightest measurable movement of the sun is equal to the movement of the two-thousand years it takes to pass through a constellation.  This is because 0.000000000000001 is the same as 100000000000000.0

Above, we plotted the values simply as colors, but when we use the actual values of the cross-summed numbers as the Y-axis, with each number advancing one step across the X-axis (time), we get a different perspective, as seen in the top image below.  The bottom image is the same plot but only using the differences between each number.

This plot uses 300,000 cross-summed data points that covers 25 minutes of observation.

<center><img src='../Images/CS-totals.png' style='width:100%'/></center>

Surprisingly, the top image appears to be a cross-sectional diagram of a Fresnel lens!

This raises the questions:

- Where do these patterns come from?
- Do they tell us anything about the thing being measured?
- Given that these patterns are the same that describe the propagation and near-field diffraction of light (i.e., Fresnel diffraction), can we apply any other attributes of light to whatever we are observing?

**Additional details for the curious**

Below are some of the visual results of the plot.

These plots are of data captured every 0.005 and .01 seconds, and we only look at the cross-summed values that are prime numbers (2,3,5,7), but the results were the same when using all numbers 0-9.  These twelve plots represent sampled data from each month of the year at the same time.

<center><img src='../Images/sun-moon-patterns.png' style='width:100%'/></center>

It is interesting to see how the 0.005s look slightly “zoomed out” compared to the 0.01s. Also interesting is how the plot pattern and the pattern of wood grain is so similar, suggesting the source of these patterns also share a common process, at least mathematically.

We see another pattern if we change the time between samples from microseconds to days.  Below are 10 sets representing 10 months with the same starting point as the sets above, but each pixel represents an entire day (86480 seconds), i.e., the position of the Sun and the Moon was recorded only once a day.  This means that the entire set represents 1,095 years.  Each plot looked almost identical and appeared completely random, but upon closer examination, they were not random at all, but a very “zoomed out” view.  It is clearer to see the pattern if we only show the blue dots of a small section of the image.

<center><img src='../Images/day-sun-moon.png' style='width:80%'/></center>

My first assumption was that the farther “out” we zoom in time, the clearer the patterns, but it seems to be the exact opposite;  the smaller the time delta, the larger the pattern.  This might make sense if we were looking at the linear difference between, say, 1.234567*0* and 1.234567*8*, as the difference would be 0.0000008, and such a small change would need a lot of samples to make itself apparent, but this does not apply here because we are cross-summing the numbers together, making the place of the digits meaningless.

Below is a comparison of the patterns at each scale.  The values above the images are the interval sampling time, and the values below are the sample’s entire duration.  No obvious pattern can be seen at 5s, but a slight pattern begins to emerge at 0.5s, becomes more apparent at 0.05s, and is most dominant at 0.005s.  A pattern is equally visible in 0.0005s but appears only as a simple oscillation or wave.  0.00005 is identical to 0.0005 because (it seems that) once we start going below 0.002, we hit the limits of resolution.  This is the point where we begin getting duplicate data because the Sun or Moon has not moved enough in the small amount of time between samples, and the smaller we go, the more duplicates we get.  For example, at 0.00001 second intervals of sampling , to get the 155,520 unique data points to create the graph, we need to sample 50,000,000 times.  This simple wave pattern is the 1<sup>st</sup> wave pattern we can detect (given the limitation of my laptop and/or the ephemeris used to calculate planetary positions).  This simple wave pattern is what then evolves into the more complex patterns.  Presumably, the difference between sample points in the wave patterns is only the rightmost last digit being increased by 1, given that we keep sampling until we get the next unique number.

<center><img src='../Images/sun-moon-grades.png' style='width:100%'/></center>

How do we have patterns when we sample at 0.01, but nothing (significant) when we sample at .05?  I think this has to do with where we are sampling from within the entire pattern.  The two images below show that the Fresnel pattern is slightly altered with time but eventually returns.  It looks like Fresnel diffraction at its most ordered point, but at its least ordered point, it looks identical to pure random data (but we assume it is just as ordered, only difficult to see that order).

<center><img src='../Images/allnumcomp.png' style='width:100%'/></center>

When the data is sampled, we have no idea where we are within the cycle of repeating patterns, so it is only by chance that we will end up in an ordered section.

For those not familiar with Fresnel diffraction, it is the way that light interferes with itself as it travels around the edge of an object

<center><img src='../Images/diffraction.png' style='width:80%'/></center>

**Digging Deeper**

Having no idea where to look for more information, I posted this to various mathematics forums, and even though the question was read by many, no one had an answer.  I then sent this question to my old friend, who is an accomplished physicist but who also considers these speculative ideas to be a waste of time, so I knew any answer he gave would include an unabashed commentary on the silliness of it all.

He did not disappoint on either front.  I’ll forego the commentary and just focus on the relevant part of his reply, which was very short.  Essentially he told me that no matter how hard you try to create random numbers from non-random data, you will always end up with some sort of a pattern.  “Why?” was my naive response, to which he replied only, “Look into Zipf’s law”.

Zipf’s law is (from Wikipedia):

>  an *empirical law*… that refers to the fact that many types of data … can be approximated with [certain types of] power law probability distributions.  Zipf distribution is related to the *zeta distribution* but is not identical.

There are 2 very significant points in this definition.  The first is that it is an *empirical law.*  Something is called an *empirical law* when it can be observed but not proven (yet).  The second important detail is that *Zipf distribution* is related to *Zeta distribution*.  We’ll get to that in a moment.

Zipf’s law was not discovered by physicists or even within the hard sciences.  It was a French stenographer, Jean-Baptiste Estoup (1868 - 1950), that first discovered the patterns of words which became Zipf’s law after it was popularized by the American linguist George Kingsley Zipf (1902 - 1950).

It seems that all languages, from every corner of the world, both modern and ancient, follow Zipf’s law in the way words are distributed in both writing and speaking (and by inference, some implicit pattern in the way we think).  We don’t need to drill into the details, but what is significant is that this same distribution pattern is also seen in city populations, solar flare intensities, protein sequences, immune receptors, the amount of traffic websites get, earthquake magnitudes, the number of times academic papers are cited, last names, the firing patterns of neural networks, ingredients used in cookbooks, the number of phone calls people received, the diameter of Moon craters, the number of people that die in wars, the popularity of opening chess moves, even the rate at which we forget… and countless more.[^198]

[^198]: Stevens, M. (2015, September 15). **The Zipf Mystery**.  Retrieved June 30, 2020, from https://www.youtube.com/watch?v=fCn8zs912OE.  The page of this video has dozens of excellent related links


<center><img src='../Images/many-zipfs.png' style='width:100%'/> </center>

In short, Zipf’s law is an example of *power laws*, and power laws touch everything in existence in one way or another.  But what does this have to do with anything?  This is where the second point applies.  The charts above are called *Zipf Distributions*, and they all have different scales of values based on the kind of data being sampled.  If we reduce all the scales to 1, we have what is called a normalized *Zipf distribution*, also known as a *Zeta distribution*.  Mathematicians use the *Riemann zeta function (RZF)* to study and test these distributions.  This function is written as  **ζ(*s*)**, where ***s*** is any complex number other than 1.

<center><img src='../Images/rzf-form.png' style='width:80%'/></center>

Related sidenote, using just prime numbers, you can also determine &pi;, but this has nothing to do with RZF:  <IMG src='../Images/math/301.svg' style=' vertical-align: middle;height:14pt;'/>.

One of the useful features of the RZF is that it can turn a *divergent* series of numbers (numbers that, when you add them together, approach infinity) into a *convergent* series (when the sum approaches a specific value, like <IMG src='../Images/math/302.svg' style=' vertical-align: middle;height:14pt;'/> or <IMG src='../Images/math/311.svg' style=' vertical-align: middle;height:14pt;'/>).  It can do this because the hypothesis uses the concept of *analytic continuation* and *complex numbers*.  You can play with this function using an online Riemann Zeta Function Calculator.  [^199]

[^199]: https://solvemymath.com/online_math_calculator/number_theory/riemann_function/index.php or https://keisan.casio.com/exec/system/1180573439, for example.

The RZF is based on the *Riemann hypothesis*, which also states that ζ(*s*)=0 only when *s* is a negative even integer or a complex number with the *real* part of <IMG src='../Images/math/304.svg' style=' vertical-align: middle;height:14pt;'/>.  This hypothesis is quite profound in how it relates to the distribution of prime numbers.  That won’t be explained here, but it is understandable when properly explained.  There are a couple of excellent videos on the subject at <https://www.youtube.com/watch?v=sD0NjbwqlYw> and <https://www.youtube.com/watch?v=d6c6uIyieoo>.

However, this 160-year-old hypothesis has yet to be proven, and because it is considered by many mathematicians to be the most important unsolved problem in pure mathematics, the Clay Mathematics Institute has a reward of US &dollar;1,000,000 to anyone who could solve it.  *(Update.  September 24, 2018.  Michael Atiyah , the 89 year old mathematician emeritus at The University of Edinburgh, claims he has proved this, but many experts doubt its validity)*

Understanding how the RZF works would (probably) help explain how and why patterns of numbers appear organically in any data set of naturally occurring samples, such as the charts above.

What value would we get if we applied the RZF to the series of square roots of natural numbers, the same numbers that define a Fresnel diffraction?  Some really smart person did exactly this [^200], and the answer is…  voilà!

[^200]: Snehal Shekatkar, **The sum of the r<sup>th</sup> roots of first n natural numbers and new formula for factorial**, 2012, arXiv:1204.0877v2 [math.NT], https://arxiv.org/abs/1204.0877v2

<center><img src='../Images/sqrt2pi.png' style='width:50%'/></center>

This is the inverse of <IMG src='../Images/math/305.svg' style=' vertical-align: middle;height:14pt;'/>, and is especially interesting because now we have a formula that fits into the *pattern-position* of Ohm’s law and Newton’s laws of motions.  This is consistent with and supports the ideas put forth earlier that archetypal functions or formulas instantiate differently depending on their context, similar to how the energy of nature interacts with itself across various contexts, as previously shown.  For clarity, we’ll refer to contextual functions that are algorithmically identical as having the same *pattern-positions* (*PP*).  An example of this, as previously shown, is the single (fractal) function with various contextual parameters that describes energy interacting with itself across various contexts.

<center><img src='../Images/lightning-3.png' style='width:100%'/></center>

In this case, as we are only looking at Ohm’s law and its 12 formulas, we see that <IMG src='../Images/math/305.svg' style=' vertical-align: middle;height:14pt;'/> has the same *pattern* as <IMG src='../Images/math/306.svg' style=' vertical-align: middle;height:14pt;'/>  or <IMG src='../Images/math/307.svg' style=' vertical-align: middle;height:14pt;'/>  at *position* 11:00 (as in the 12-hour clock) on the 12-part wheel we are using, and we can test that by plugging in the appropriate values.  The table below shows these pi-based values that seem to describe the pi-based values we are seeing with regard to Ohm’s law.  For the sake of clarity, I assigned some of the formulas to variables; otherwise, it’s too bothersome to read (or compose).  In the table below, I show Ohm’s law with some previously shown examples plus the simple math examples and then the application of <IMG src='../Images/math/305.svg' style=' vertical-align: middle;height:14pt;'/> and <IMG src='../Images/math/310.svg' style=' vertical-align: middle;height:12pt;'/>.  Those 2 values alone were enough to fill in all the missing values.  In the middle column of the table, I show the actual numbers and the formulas to the right.

<center><img src='../Images/ohmslaw-pi.png' style='width:100%'/></center>

All of this may have nothing to do with unraveling the mystery of the Fresnel pattern hidden in the data, but it is interesting nonetheless, specifically:

- ***α*** is in the same *PP* as *resistance*, *mass*, *DEFINITION*, and the 1<sup>st</sup>, and only even, prime number of 2.  2 is the only number in these formulas unrelated to &pi;.  In the RZF, the inverse of this prime number,  <IMG src='../Images/math/309.svg' style=' vertical-align: middle;height:14pt;'/>, is the only value that returns 0, as in ζ(2 <sup>-1</sup>)=0, or ζ(<IMG src='../Images/math/309.svg' style=' vertical-align: middle;height:14pt;'/>)=0.  In the RZF, this value marks the center of the symmetry for all numbers produced by the RZF, natural and complex.  In other words, the <IMG src='../Images/math/309.svg' style=' vertical-align: middle;height:14pt;'/> point, not the 0 point, is the pivotal point that mirrors all the values on one side of the <IMG src='../Images/math/309.svg' style=' vertical-align: middle;height:14pt;'/> mark and which are reflected on the equal but opposite side of <IMG src='../Images/math/309.svg' style=' vertical-align: middle;height:14pt;'/>.  This is relevant because the RZF seems to be very related to the creation of the Fresnel pattern.

- ***β***  is the opposite *PP* of ***α*** and the inverse of ***γ*** and occupies the *PP* of *CONTRIBUTION*,  *current*, *the speed of light*, and the next prime number, 3.

- ***γ*** is defined as <IMG src='../Images/math/310.svg' style=' vertical-align: middle;height:10pt;'/>, which is also the result of RZF of the square roots of all natural numbers greater than 1, which is the sequence of values that defines a Fresnel lens and our distance-delta plots.  That sequence of natural numbers is created by ζ(-1).  The *PP* of ***γ*** is that of *volts* (the amount of potential that exists between two opposing limits) and of *NEGOTIATION* and shares the *PP* with 6.

- ***&pi;*** is in the same *PP* as *Power* (electrical),  *Energy*, and the *white-dot* of the tholon where all three points combine to create a 3D tholon.  However, it could also represent the new N-state that is created on the spectrum between ***α*** and ***β*** (or *DEFINE* and *CONTRIBUTE*), as the tetrahedron can not become 3D until the child N-state is created.

- The spectrum of ***α*** and ***β*** where all new N-states appear is also the spectrum between the only two prime numbers, 2 and 3 (6 and 18).

- ***α*** and ***β*** are in the same *PP* as the prime numbers, and the remaining two variables are products of these two numbers.  In this specific case, for the pi-based formulas to work, the value of 2 must be in the *PP* of 2.  (See *Squares and Square Roots* chapter in [Appendix C, “Tholonic Math”](#Appendix-C:-Tholonic-Math_) for more about the miracle of the number 2)

  We also see that ***γ*** equals <IMG src='../Images/math/313.svg' style=' vertical-align: middle;height:10pt;'/>, which is the volume of a four-sided pyramid with a base length and height of &pi; (because &pi;<sup>3</sup>/3 = 10.3354255600999).

## The Cornu Spiral

While the manner in which the cross-summed numbers create a diffraction pattern may be a mystery (to me), how diffraction patterns are created are not.  Properly described, it would require a lot of math which we won’t get into here, but a quick search on “What is the Cornu’s spiral method for diffraction pattern?” will reveal all to the more curious.  In short, because we know that the intensity of light at any point is always proportional to 2 values known as the *Fresnel integrals* <IMG src='../Images/math/314.svg' style=' vertical-align: middle;height:28pt;'/>, we can plot the intensity of each point along the diffraction pattern on a 2-Dimensional plot.  When we do this, we end up with an amazing figure called the *Cornu Spiral*, shown below as “2D Cornu Spiral (Fresnel)”.

Another interesting thing about the Cornu Spiral is that it also describes the path of the sun over the course of the year (from Earth’s perspective)[^201], which is pretty poetic.  It appears as though the Cornu spiral describes not only how light and matter interact on the nanometer scale but also on the planetary scale, at least in one sense.

[^201]: Saad-Cook, J., Ross, C., Holt, N., & Turrell, J. (1988). “**Touching the Sky: Artworks using Natural Phenomena, Earth, Sky and Connections to Astronomy**”. *Leonardo* *21*(2), 123-134. [https://www.muse.jhu.edu/article/600628](https://muse.jhu.edu/article/600628). Charles Ross, the creator, describes: “1972.  I had placed this simple lens set-up on the roof so the sun would burn a path across a wooden plank as the day progressed.  The idea was to collect a portrait of the weather each day.  As the work progressed, I noticed that the burn’s curvature was changing with the seasons.  We took photos of the burns and placed them end to end following their curvature to see what a year’s worth looked like.  The sum of days generated a double spiral figure.  At first, it did not make any sense-this primitive lens set-up was producing a complex spiral shape.  A few of the astronomers I showed it to said, “Well, it must be coming from somewhere, but we have no idea what it is”.  Most of the scientists insisted that there had to be some anomaly in the set-up and that the shape had nothing to do with astronomy -just some weirdness in the lens.  In reality, it made no difference at all if the lens faced one way or the other as long as it faced generally toward south.  The elements of the spiral are in sunlight itself; it was an archetypal image falling from the sky.  I finally contacted Kenneth Franklin at the Hayden Planetarium.  He directed me to the Naval Observatory, where LeRoy Doggett, an astronomer with the Nautical Almanac office…”.  Authors note: This Sun Spiral was pieced together manually from many separate samples and is an approximation of the Sun’s path.

Not surprisingly, the Riemann Zeta Function also creates not just one Cornu Spiral but an entire series of spirals, as shown in “Cornu Spiral (RZF)”, that emerge from nothing and continues to expand from within itself.

The *x* and the *y* values are the result of a function based on a single value, as in *x(t)* and *y(t)* of the Fresnel Integrals, but there can be a third dimension based on *t*.  When this new *z(t)* dimension is proportional to the *x* and *y* dimensions, a cone is created on the z-axis, which might be related to the diminishing angles of the diffraction pattern in the “Slightly zoomed out” plot of the cross-summed data patterns shown above.

<center><img src='../Images/cornu.png' style='width:100%'/></center>

So, by saying the following…

- The Cornu Spiral describes the diffraction pattern.
- The RZF describes a Cornu spiral.
- The RZF is a normalized version of the Zipf Function.
- The light of the sun hitting Earth creates a Cornu-ish spiral over the course of a year.

… we can relate our mystery pattern to several other patterns, including Newton’s 2<sup>nd</sup>, but the most dominant ones have to do with the nature of light.

In one way, it is like the cross-summed numbers are similar to photons in that the individual photons create the diffraction pattern, just like the individual numbers of our data also create the diffraction pattern.  Both of these “particles” (photons and numbers) are presumably following some of the same rules in some fashion if we are to judge them by their resulting patterns.  Given my lack of training in this area, I can only wonder if photons’ wave/particle properties also apply (contextually) to cross-summed numbers or numbers in general.  Perhaps they are somehow related or similar to *Feynman Sunshine Numbers*, which relates prime numbers and photons, among other things.  These numbers include RZF values that appear in the description of sunshine, ancient relics of the Big Bang, and the theory of photons, electrons, and positrons.

## Cross Sum Patterns

It seems useful to say something more about cross-summed numbers.

Cross-summing multi-place numbers like a carnival numerologist will generate seemingly meaningless data, at least with respect to the quantitative significance of that data, but it will have plenty of information about the nature or quality of the original number.  For example, a single-digit cross-summed value preserves many of the same properties as the original uncross-summed number, no matter how large that number is.  A cross-sum divisible by 3 means the entire number is divisible by 3, and if divisible by 9, then the entire number is divisible by 9.  We all know that if the last digit of a number is 2, then that number is divisible by 2, but it is also true if the cross-sum of the last 2 digits of a number equals 4, then that number is divisible by 4.  Testing for divisible by 8 can also be done by cross-sums but is a bit more complicated.  You join the 2 leftmost digits, multiply by 2, and then add the rightmost number.  For example, if a number ends in 464, such as 7464, then 2&times;(**46**)+**4**=96=12&times;8.  Now we know that 7464 is also a multiple of 8, which is the case; 8&times;933=7464.  

10 is obvious, but 11 is very interesting.  If we have the number 5025669, to test for divisibility by 11, we reverse the number, giving us 9665205.  We then do an *alternating* cross-sum like so:  9-6+6-5+2-0+5=11, so 5025669 is divisible by 11 (5025669&div;11=456879).  This is interesting because 11 cross-sums to 2, and we can use the number of places used to test for divisibility as exponents of 2 (2<sup>0</sup>=1, 2<sup>1</sup>=2, 2<sup>2</sup>=4, 2<sup>3</sup>=8).  With these numbers, which is a binary expansion,  we can apply the oscillating functions or - and + to get a final number, and if that number is 11, then the original number is divisible by 11!

Divisibility by 7 is also interesting because it uses recursive cross-sums.  To test the number 371, we take the rightmost digit and multiply it by 2, then subtract that value from the remaining digits:

37 - (2×1) = 35

Then we do that again on the answer:

3 - (2 × 5) = -7;

Cross-summing is like a form of *qualitative* math.  In all these examples, the cross-summing told us something about the *quality* of the number, such as how it can be divided, regardless of the *quantity* of the number.  

If we have patterns of non-random numbers, we can use cross-summing to learn of some quality of that pattern.

For example, if we create a list of number that increases by 8, as in 8, 16, 24, 32, 40, 48, 56, 64, 72, etc., and then cross-sum them as follows:

<center><img src='../Images/by8rotate.png' style='width:50%'/></center>

&hellip;we get a resulting sequence of 8, 7, 6, 5, 4, 3, 2, 1, 9 which continually repeats itself.

Our original data was sequential because it was tracking the linear movement of planets, so that means that the progression of values will always represent progressive points on a linear path, with each value being slightly larger (in this case) than the previous value, but when we cross-sum these values, all spacial or temporal information is lost leaving only the pattern of the relationship of the numbers.  For example, 10 is larger than 9 but cross-sums to 1.  Here, 1 represents the *lower octave* (for lack of a better term) of 10.  Cross-summing essentially lowers all the numbers to the same octave.  We see this in the number matrix below (left), as any consecutive sequence of digits will always repeat one of the nine patterns shown in the matrix.  While this removes a lot of quantitative data, it does not remove the relationship between the data.  In fact, it makes that relationship clearer, much like listening to a 10-octave piano piece in only 1 octave.

This number matrix shows the repeating pattern of every sequence of numbers that increases by the number in the left column.  The chart on the right shows the changing progression of each row in the matrix is only 6 stages of transformation between the straight line at the bottom (1) and the perfectly ordered line at the top (8).  The line above that (9) are the totals of each line, which also happens to be exactly the same pattern as line 8.  The graph at the bottom shows these same numbers but non-stacked and smoothed, and here you can see the symmetry of the progressive changes.  This example applies to any sequence of integers.

<center><img src='../Images/crosssumpatterns2.png' style='width:90%'/></center>

In our example of the series of numbers based on multiples of 8, we have two types of numbers; the quantitative values and the cross-summed values that represent their “position” or relation to other numbers within the context of a base-10 number system.  In the charts below, the top-left chart shows both of these values as 2-dimensional and shows how the quantitative value can decrease as the cross-sum value increases.  The top-right chart shows the values of 2 dimensions plotted as x and y, which shows that the difference between the diverging values is linear.

Further below, the left chart is a plot of what appears to be un-patterned data, but when we reduce it to one octave by cross-summing, we see a very clear pattern.

<center><img src='../Images/crossnumoctaves8.png' style='width:100%'/></center>

The point of this is to demonstrate how there can be hidden patterns in seemingly un-patterned data that has nothing to do with how it exists in time and space.

Attempts were made to replicate the patterns that appeared in the planetary data with various other inputs, such as incremental counting, the number of seconds from some moment, a number and some function of that number, such as square root, but nothing was able to get even close to the Sun/Moon patterns.  This suggests that the Fresnel pattern is not solely an inherent cross-sum pattern but a result of the source data.  If that is the case, could it be possible that the Fresnel pattern is a property of the movement of the Sun and the Moon or at least 2 rotating bodies in the same system?

<center><img src='../Images/stacker64.png' style='width:100%'/></center>

The image above is more fun than informative because it fuels the imagination.  The top left and right charts show 64 samples of the position of the Sun to 14 places.  The values of each place are then plotted as one set of data.  For example, if there are 3 samples of data of 1.23, 4.56, and 7.89, we plot the 1<sup>st</sup> line as 1,4,7, the 2<sup>nd</sup> line as 2,5,8 and the 3<sup>rd</sup> line as 3,6,9.  Were this a live, real-time plot, we would see the outermost circle (or top-most line) changing thousands of times per second and the innermost (or bottom) changing every couple of months.  If we plotted time instead of space to 14 places, the outer (or top) would change a million times a second, and the inner (or bottom) would change once every 11 days.  Looking at the upper left image, it is very interesting (although probably statistically meaningless) that there is an obvious pattern in the first 6 values, and with the 7<sup>th</sup>, that pattern quickly begins to degrade. 

The bottom images (of the image above) is simply a graph where each value is a dot over the course of 3,000 samples.

<center><img src='../Images/cstrees.png' style='width:100%'/></center>

The images above were created by plotting each digit of the Sun’s position (x-axis) and showing some interesting patterns worth highlighting.

- In ***Img. 1***, we begin with the first number at the bottom.  Each subsequent digit is plotted *3&times;number* degrees to the left or right, with even numbers to the right and odd numbers to the left.  For example, the number 9 would be plotted 27 degrees to the left, and the number 8 would be plotted 24 degrees to the right.  The width of the line is relative to the digit’s place, so 1.0 is wider than 0.1, which is wider the 0.01, etc.  The image in the 2<sup>nd</sup row, ***Img.  1a***, is the same  algorithm but based on random numbers rather than the Sun’s position.  The reason for odd=left and even=right was to see what pattern we would get if we applied one property to even numbers and a different property to odd numbers.   We can see this same attribution in the ancient Taoist tradition of even as yin and odd as yang and in the ancient Greek tradition, where even numbers were feminine in nature and odd numbers masculine[^202].  If there was any validity to this attribution, then we would expect to see a pattern common in nature, which is exactly what we get.  ***Img.  1b*** is the same as ***Img.  1a***, but where the initial direction of each line is random.
- ***Img. 2*** is similar to ***Img. 1***, except each number is plotted adjacent to the previous number (and the colors were changed, the deviation was lessened, and the length of the plot was slightly shortened).
- ***Img. 3*** is something entirely different.  Rather than using the position of the Sun, we used the recurring cross-summed patterns of the sequence of numbers when we increased counting by 1 through 9 (as shown in the number matrix above).  The image below ,***Img.  3a***, is that same sequence but with a much larger value so as to see its larger pattern.  Interestingly, we end up with three distinct groups;  1,4,7 (cross-sum=12=3),  2,5,8 (cross-sum=15=6), and 3,6 (cross-sum=9).

[^202]: Nishiyama, Yutaka. “**A Study of Odd- and Even-Number Cultures.**” *Bulletin of Science, Technology & Society* 26, no. 6 (2006): 479-84.  doi:10.1177/0270467606295408.
